{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e4369b",
   "metadata": {},
   "source": [
    "## Preprocessing Hasil Crawling\n",
    "\n",
    "### Preprocessing Hasil Crawling PTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce332c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.2-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.8.7-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting Sastrawi\n",
      "  Using cached Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
      "Collecting pyspellchecker\n",
      "  Using cached pyspellchecker-0.8.3-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\infinix ebc\\env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Using cached regex-2025.9.1-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Using cached murmurhash-1.0.13-cp313-cp313-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Using cached cymem-2.0.11-cp313-cp313-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Using cached preshed-3.0.10-cp313-cp313-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Using cached thinc-8.3.6-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Using cached srsly-2.5.1-cp313-cp313-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Using cached typer-0.17.4-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\infinix ebc\\env\\lib\\site-packages (from spacy) (2.32.5)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Using cached pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\infinix ebc\\env\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\infinix ebc\\env\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\infinix ebc\\env\\lib\\site-packages (from spacy) (25.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached pydantic_core-2.33.2-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\infinix ebc\\env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\infinix ebc\\env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\infinix ebc\\env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\infinix ebc\\env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\infinix ebc\\env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached blis-1.3.0-cp313-cp313-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\infinix ebc\\env\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached cloudpathlib-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached smart_open-7.3.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached wrapt-1.17.3-cp313-cp313-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached marisa_trie-1.3.1-cp313-cp313-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\infinix ebc\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\infinix ebc\\env\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\infinix ebc\\env\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Downloading pandas-2.3.2-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.0 MB 3.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 3.5 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.8/11.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.7/11.0 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.5/11.0 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.8/11.0 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.6/11.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.4/11.0 MB 3.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/11.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 3.8 MB/s  0:00:02\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached spacy-3.8.7-cp313-cp313-win_amd64.whl (13.9 MB)\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.11-cp313-cp313-win_amd64.whl (39 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Using cached murmurhash-1.0.13-cp313-cp313-win_amd64.whl (24 kB)\n",
      "Using cached preshed-3.0.10-cp313-cp313-win_amd64.whl (115 kB)\n",
      "Using cached pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.1-cp313-cp313-win_amd64.whl (630 kB)\n",
      "Using cached thinc-8.3.6-cp313-cp313-win_amd64.whl (1.7 MB)\n",
      "Using cached blis-1.3.0-cp313-cp313-win_amd64.whl (6.3 MB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading numpy-2.3.3-cp313-cp313-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.8 MB 4.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.6/12.8 MB 4.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.6/12.8 MB 4.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.7/12.8 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.7/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.8/12.8 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.6/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.3/12.8 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.1/12.8 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.2/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.2/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.8/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 4.2 MB/s  0:00:03\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typer-0.17.4-py3-none-any.whl (46 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached cloudpathlib-0.22.0-py3-none-any.whl (61 kB)\n",
      "Using cached smart_open-7.3.1-py3-none-any.whl (61 kB)\n",
      "Using cached Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
      "Using cached pyspellchecker-0.8.3-py3-none-any.whl (7.2 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached marisa_trie-1.3.1-cp313-cp313-win_amd64.whl (139 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached regex-2025.9.1-cp313-cp313-win_amd64.whl (275 kB)\n",
      "Using cached rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached wrapt-1.17.3-cp313-cp313-win_amd64.whl (38 kB)\n",
      "Installing collected packages: Sastrawi, pytz, cymem, wrapt, wasabi, tzdata, typing-inspection, tqdm, spacy-loggers, spacy-legacy, shellingham, regex, pyspellchecker, pydantic-core, numpy, murmurhash, mdurl, marisa-trie, joblib, cloudpathlib, click, catalogue, annotated-types, srsly, smart-open, pydantic, preshed, pandas, nltk, markdown-it-py, language-data, blis, rich, langcodes, confection, typer, thinc, weasel, spacy\n",
      "\n",
      "   ----------------------------------------  0/39 [Sastrawi]\n",
      "   ----------------------------------------  0/39 [Sastrawi]\n",
      "   ----------------------------------------  0/39 [Sastrawi]\n",
      "   ----------------------------------------  0/39 [Sastrawi]\n",
      "   - --------------------------------------  1/39 [pytz]\n",
      "   - --------------------------------------  1/39 [pytz]\n",
      "   - --------------------------------------  1/39 [pytz]\n",
      "   - --------------------------------------  1/39 [pytz]\n",
      "   - --------------------------------------  1/39 [pytz]\n",
      "   --- ------------------------------------  3/39 [wrapt]\n",
      "   ---- -----------------------------------  4/39 [wasabi]\n",
      "   ----- ----------------------------------  5/39 [tzdata]\n",
      "   ----- ----------------------------------  5/39 [tzdata]\n",
      "   ----- ----------------------------------  5/39 [tzdata]\n",
      "   ----- ----------------------------------  5/39 [tzdata]\n",
      "   ------- --------------------------------  7/39 [tqdm]\n",
      "   ------- --------------------------------  7/39 [tqdm]\n",
      "   ------- --------------------------------  7/39 [tqdm]\n",
      "   ------- --------------------------------  7/39 [tqdm]\n",
      "   -------- -------------------------------  8/39 [spacy-loggers]\n",
      "   --------- ------------------------------  9/39 [spacy-legacy]\n",
      "   --------- ------------------------------  9/39 [spacy-legacy]\n",
      "   ---------- ----------------------------- 10/39 [shellingham]\n",
      "   ----------- ---------------------------- 11/39 [regex]\n",
      "   ------------- -------------------------- 13/39 [pydantic-core]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   -------------- ------------------------- 14/39 [numpy]\n",
      "   --------------- ------------------------ 15/39 [murmurhash]\n",
      "   ------------------ --------------------- 18/39 [joblib]\n",
      "   ------------------ --------------------- 18/39 [joblib]\n",
      "   ------------------ --------------------- 18/39 [joblib]\n",
      "   ------------------ --------------------- 18/39 [joblib]\n",
      "   ------------------ --------------------- 18/39 [joblib]\n",
      "   ------------------ --------------------- 18/39 [joblib]\n",
      "   ------------------ --------------------- 18/39 [joblib]\n",
      "   ------------------ --------------------- 18/39 [joblib]\n",
      "   ------------------ --------------------- 18/39 [joblib]\n",
      "   ------------------- -------------------- 19/39 [cloudpathlib]\n",
      "   ------------------- -------------------- 19/39 [cloudpathlib]\n",
      "   -------------------- ------------------- 20/39 [click]\n",
      "   -------------------- ------------------- 20/39 [click]\n",
      "   --------------------- ------------------ 21/39 [catalogue]\n",
      "   ----------------------- ---------------- 23/39 [srsly]\n",
      "   ----------------------- ---------------- 23/39 [srsly]\n",
      "   ----------------------- ---------------- 23/39 [srsly]\n",
      "   ----------------------- ---------------- 23/39 [srsly]\n",
      "   ----------------------- ---------------- 23/39 [srsly]\n",
      "   ----------------------- ---------------- 23/39 [srsly]\n",
      "   ----------------------- ---------------- 23/39 [srsly]\n",
      "   ----------------------- ---------------- 23/39 [srsly]\n",
      "   ----------------------- ---------------- 23/39 [srsly]\n",
      "   ----------------------- ---------------- 23/39 [srsly]\n",
      "   ----------------------- ---------------- 23/39 [srsly]\n",
      "   ------------------------ --------------- 24/39 [smart-open]\n",
      "   ------------------------- -------------- 25/39 [pydantic]\n",
      "   ------------------------- -------------- 25/39 [pydantic]\n",
      "   ------------------------- -------------- 25/39 [pydantic]\n",
      "   ------------------------- -------------- 25/39 [pydantic]\n",
      "   ------------------------- -------------- 25/39 [pydantic]\n",
      "   ------------------------- -------------- 25/39 [pydantic]\n",
      "   ------------------------- -------------- 25/39 [pydantic]\n",
      "   ------------------------- -------------- 25/39 [pydantic]\n",
      "   ------------------------- -------------- 25/39 [pydantic]\n",
      "   ------------------------- -------------- 25/39 [pydantic]\n",
      "   ------------------------- -------------- 25/39 [pydantic]\n",
      "   ------------------------- -------------- 25/39 [pydantic]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   --------------------------- ------------ 27/39 [pandas]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ---------------------------- ----------- 28/39 [nltk]\n",
      "   ----------------------------- ---------- 29/39 [markdown-it-py]\n",
      "   ----------------------------- ---------- 29/39 [markdown-it-py]\n",
      "   ----------------------------- ---------- 29/39 [markdown-it-py]\n",
      "   ----------------------------- ---------- 29/39 [markdown-it-py]\n",
      "   ----------------------------- ---------- 29/39 [markdown-it-py]\n",
      "   ----------------------------- ---------- 29/39 [markdown-it-py]\n",
      "   ------------------------------ --------- 30/39 [language-data]\n",
      "   ------------------------------ --------- 30/39 [language-data]\n",
      "   ------------------------------ --------- 30/39 [language-data]\n",
      "   ------------------------------ --------- 30/39 [language-data]\n",
      "   ------------------------------ --------- 30/39 [language-data]\n",
      "   ------------------------------ --------- 30/39 [language-data]\n",
      "   ------------------------------ --------- 30/39 [language-data]\n",
      "   ------------------------------ --------- 30/39 [language-data]\n",
      "   ------------------------------ --------- 30/39 [language-data]\n",
      "   ------------------------------ --------- 30/39 [language-data]\n",
      "   ------------------------------- -------- 31/39 [blis]\n",
      "   -------------------------------- ------- 32/39 [rich]\n",
      "   -------------------------------- ------- 32/39 [rich]\n",
      "   -------------------------------- ------- 32/39 [rich]\n",
      "   -------------------------------- ------- 32/39 [rich]\n",
      "   -------------------------------- ------- 32/39 [rich]\n",
      "   -------------------------------- ------- 32/39 [rich]\n",
      "   -------------------------------- ------- 32/39 [rich]\n",
      "   -------------------------------- ------- 32/39 [rich]\n",
      "   --------------------------------- ------ 33/39 [langcodes]\n",
      "   ---------------------------------- ----- 34/39 [confection]\n",
      "   ----------------------------------- ---- 35/39 [typer]\n",
      "   ----------------------------------- ---- 35/39 [typer]\n",
      "   ----------------------------------- ---- 35/39 [typer]\n",
      "   ------------------------------------ --- 36/39 [thinc]\n",
      "   ------------------------------------ --- 36/39 [thinc]\n",
      "   ------------------------------------ --- 36/39 [thinc]\n",
      "   ------------------------------------ --- 36/39 [thinc]\n",
      "   ------------------------------------ --- 36/39 [thinc]\n",
      "   ------------------------------------ --- 36/39 [thinc]\n",
      "   ------------------------------------ --- 36/39 [thinc]\n",
      "   ------------------------------------ --- 36/39 [thinc]\n",
      "   ------------------------------------ --- 36/39 [thinc]\n",
      "   ------------------------------------ --- 36/39 [thinc]\n",
      "   ------------------------------------ --- 36/39 [thinc]\n",
      "   ------------------------------------ --- 36/39 [thinc]\n",
      "   ------------------------------------ --- 36/39 [thinc]\n",
      "   ------------------------------------ --- 36/39 [thinc]\n",
      "   ------------------------------------- -- 37/39 [weasel]\n",
      "   ------------------------------------- -- 37/39 [weasel]\n",
      "   ------------------------------------- -- 37/39 [weasel]\n",
      "   ------------------------------------- -- 37/39 [weasel]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   -------------------------------------- - 38/39 [spacy]\n",
      "   ---------------------------------------- 39/39 [spacy]\n",
      "\n",
      "Successfully installed Sastrawi-1.0.1 annotated-types-0.7.0 blis-1.3.0 catalogue-2.0.10 click-8.2.1 cloudpathlib-0.22.0 confection-0.1.5 cymem-2.0.11 joblib-1.5.2 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.3.1 markdown-it-py-4.0.0 mdurl-0.1.2 murmurhash-1.0.13 nltk-3.9.1 numpy-2.3.3 pandas-2.3.2 preshed-3.0.10 pydantic-2.11.9 pydantic-core-2.33.2 pyspellchecker-0.8.3 pytz-2025.2 regex-2025.9.1 rich-14.1.0 shellingham-1.5.4 smart-open-7.3.1 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 tqdm-4.67.1 typer-0.17.4 typing-inspection-0.4.1 tzdata-2025.2 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.3\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.5/12.8 MB 3.9 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 4.4 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.6/12.8 MB 4.7 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 4.7 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.2/12.8 MB 4.4 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 4.6 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.0/12.8 MB 4.7 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.8/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 4.4 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.7/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.2/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 4.2 MB/s  0:00:03\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas nltk spacy Sastrawi pyspellchecker\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b10e798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\INFINIX\n",
      "[nltk_data]     EBC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data total: 14664\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstrak_id_clean</th>\n",
       "      <th>abstrak_en_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[abstrak, implementasi, fungsi, legislasi, dpr...</td>\n",
       "      <td>[abstract, implementation, legislation, parlia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[badan, usaha, milik, negara, bumn, badan, usa...</td>\n",
       "      <td>[state, own, enterprise, business, entity, par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[narkoba, henti, henti, dengar, media, televis...</td>\n",
       "      <td>[drug, case, endlessly, hear, television, radi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[produk, elektronik, benda, gerak, hasil, pros...</td>\n",
       "      <td>[electronic, product, object, move, production...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    abstrak_id_clean  \\\n",
       "0  [abstrak, implementasi, fungsi, legislasi, dpr...   \n",
       "1  [badan, usaha, milik, negara, bumn, badan, usa...   \n",
       "2  [narkoba, henti, henti, dengar, media, televis...   \n",
       "3  [produk, elektronik, benda, gerak, hasil, pros...   \n",
       "4                                                 []   \n",
       "\n",
       "                                    abstrak_en_clean  \n",
       "0  [abstract, implementation, legislation, parlia...  \n",
       "1  [state, own, enterprise, business, entity, par...  \n",
       "2  [drug, case, endlessly, hear, television, radi...  \n",
       "3  [electronic, product, object, move, production...  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.corpus import stopwords\n",
    "from spellchecker import SpellChecker\n",
    "import spacy\n",
    "\n",
    "# Download stopwords (sekali saja)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# === Load dataset ===\n",
    "pta_all = pd.read_csv(\"Data/pta_all.csv\")\n",
    "\n",
    "# === Stopwords ===\n",
    "stopwords_id = set(stopwords.words(\"indonesian\"))\n",
    "stopwords_en = set(stopwords.words(\"english\"))\n",
    "\n",
    "# === Stemmer Indonesia ===\n",
    "factory = StemmerFactory()\n",
    "stemmer_id = factory.create_stemmer()\n",
    "\n",
    "# === Spell checker English ===\n",
    "spell_en = SpellChecker(language=\"en\")\n",
    "\n",
    "# ========================\n",
    "# Fungsi Preprocessing Indo\n",
    "# ========================\n",
    "def preprocess_text_id(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # (2) Hapus tanda baca & simbol\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text.lower())\n",
    "    # (5) Tokenisasi\n",
    "    tokens = text.split()\n",
    "    if not tokens:\n",
    "        return []\n",
    "    # (1) Stopword removal\n",
    "    tokens = [w for w in tokens if w not in stopwords_id]\n",
    "    if not tokens:\n",
    "        return []\n",
    "    # (4) Stemming dengan Sastrawi\n",
    "    tokens = [stemmer_id.stem(w) for w in tokens]\n",
    "    return tokens\n",
    "\n",
    "# ========================\n",
    "# Fungsi Preprocessing English (versi aman)\n",
    "# ========================\n",
    "def preprocess_text_en(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # (2) Hapus tanda baca & simbol\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text.lower())\n",
    "    # (5) Tokenisasi\n",
    "    tokens = text.split()\n",
    "    if not tokens:\n",
    "        return []\n",
    "    \n",
    "    # (3) Cek ejaan pembakuan kata (hindari None, pastikan string)\n",
    "    corrected = []\n",
    "    for w in tokens:\n",
    "        corr = spell_en.correction(w)\n",
    "        if corr is None:      # kalau None â†’ pakai kata asli\n",
    "            corr = w\n",
    "        corrected.append(str(corr))\n",
    "    tokens = corrected\n",
    "    \n",
    "    # (1) Stopword removal\n",
    "    tokens = [w for w in tokens if w not in stopwords_en]\n",
    "    if not tokens:\n",
    "        return []\n",
    "    \n",
    "    # (4) Lematisasi dengan spaCy (hanya kalau ada token valid)\n",
    "    text_joined = \" \".join(tokens).strip()\n",
    "    if not text_joined:\n",
    "        return []\n",
    "    doc = nlp(text_joined)\n",
    "    tokens = [token.lemma_ for token in doc]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# === Terapkan ke kolom PTA ===\n",
    "pta_all[\"abstrak_id_clean\"] = pta_all[\"abstrak_id\"].apply(preprocess_text_id)\n",
    "pta_all[\"abstrak_en_clean\"] = pta_all[\"abstrak_en\"].apply(preprocess_text_en)\n",
    "\n",
    "# === Simpan hasil ===\n",
    "pta_all.to_csv(\"preprocessing_pta_all.csv\", index=False)\n",
    "\n",
    "# Contoh hasil\n",
    "print(\"Jumlah data total:\", len(pta_all))\n",
    "pta_all[[\"abstrak_id_clean\", \"abstrak_en_clean\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a886e4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prodi</th>\n",
       "      <th>abstrak_id_clean</th>\n",
       "      <th>abstrak_en_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3207</th>\n",
       "      <td>Ilmu Kelautan</td>\n",
       "      <td>['teliti', 'rumus', 'produksi', 'tingkat', 'minta', 'hambat', 'produksi', 'tidak', 'rempa', 'mou...</td>\n",
       "      <td>['study', 'problem', 'formulation', 'production', 'increase', 'high', 'permintaanpun', 'occur', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4256</th>\n",
       "      <td>Manajemen</td>\n",
       "      <td>['abstrak', 'dasar', 'hasil', 'observasi', 'teliti', 'tenaga', 'didik', 'milik', 'motivasi', 'ke...</td>\n",
       "      <td>['abstract', 'job', 'placement', 'urgent', 'matter', 'motivate', 'staff', 'work', 'place', 'yet'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8830</th>\n",
       "      <td>Ilmu Komunikasi</td>\n",
       "      <td>['abstrak', 'skripsi', 'judul', 'strategi', 'komunikasi', 'bpjs', 'sehat', 'puas', 'serta', 'bpj...</td>\n",
       "      <td>['abstract', 'thesis', 'entitle', 'communication', 'strategy', 'boy', 'kesehatan', 'boys', 'kese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6853</th>\n",
       "      <td>Teknik Informatika</td>\n",
       "      <td>['teknologi', 'mobile', 'game', 'kembang', 'pesat', 'mobile', 'game', 'milik', 'minat', 'kalang'...</td>\n",
       "      <td>['mobile', 'game', 'technology', 'grow', 'rapidly', 'mobile', 'game', 'lot', 'enthusiast', 'vari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>Agribisnis</td>\n",
       "      <td>['lurah', 'tal', 'lurah', 'kota', 'diri', 'sentra', 'buat', 'takwa', 'jajan', 'khas', 'kota', 'd...</td>\n",
       "      <td>['tinalan', 'urban', 'village', 'village', 'locate', 'city', 'keri', 'center', 'make', 'tofu', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>Teknologi Industri Pertanian</td>\n",
       "      <td>['kendali', 'mutu', 'proses', 'produksi', 'kerupuk', 'pul', 'tuju', 'mengi', 'dentifikasi', 'fak...</td>\n",
       "      <td>['quality', 'control', 'production', 'process', 'aim', 'wheeze', 'puli', 'cracker', 'identify', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10778</th>\n",
       "      <td>Ekonomi Syariah</td>\n",
       "      <td>['skripsi', 'judul', 'analis', 'pengaruh', 'strategi', 'srgmentasi', 'targeting', 'positioning',...</td>\n",
       "      <td>['study', 'entitle', 'analysis', 'influence', 'segmentation', 'target', 'position', 'strategy', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>Pgsd</td>\n",
       "      <td>['teliti', 'tuju', 'nilai', 'nilai', 'karakter', 'ekstrakurikuler', 'pencak', 'silat', 'tapak', ...</td>\n",
       "      <td>['purpose', 'research', 'understand', 'martial', 'art', 'tapas', 'ekstracuricullar', 'build', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>Agroteknologi</td>\n",
       "      <td>['abstrak', 'asap', 'cair', 'tempurung', 'kelapa', 'hasil', 'kondensasi', 'pirolisis', 'bahan', ...</td>\n",
       "      <td>['abstract', 'liquid', 'smoke', 'coconut', 'shell', 'result', 'condensation', 'pyrolysis', 'orga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>Agribisnis</td>\n",
       "      <td>['teliti', 'kabupaten', 'bangkal', 'tuju', 'karakteristik', 'responden', 'karakteristik', 'usaha...</td>\n",
       "      <td>['study', 'aim', 'analyze', 'characteristic', 'respondent', 'business', 'characteristic', 'jasmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11885</th>\n",
       "      <td>Pgsd</td>\n",
       "      <td>['teliti', 'dilatarbelakangi', 'kurangnnya', 'media', 'ajar', 'ajar', 'ipa', 'sdn', 'kalijaten',...</td>\n",
       "      <td>['research', 'motivate', 'lack', 'learn', 'medium', 'science', 'learn', 'son', 'kalijaten', 'dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10146</th>\n",
       "      <td>Sastra Inggris</td>\n",
       "      <td>['teliti', 'fokus', 'kohesi', 'leksikal', 'temu', 'lirik', 'lagu', 'jung', 'teliti', 'tuju', 'je...</td>\n",
       "      <td>['study', 'focus', 'lexical', 'cohesion', 'word', 'find', 'jung', 'song', 'lyric', 'study', 'aim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9033</th>\n",
       "      <td>Ilmu Komunikasi</td>\n",
       "      <td>['tuju', 'teliti', 'proses', 'komunikasi', 'non', 'verbal', 'karyawan', 'sandang', 'tuna', 'wica...</td>\n",
       "      <td>['purpose', 'research', 'know', 'nonverbal', 'communication', 'employee', 'speech', 'impair', 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513</th>\n",
       "      <td>Akuntansi</td>\n",
       "      <td>['teliti', 'tuju', 'uji', 'pengaruh', 'profitabilitas', 'leverage', 'ungkap', 'corporate', 'sosi...</td>\n",
       "      <td>['study', 'aim', 'examine', 'effect', 'profitability', 'leverage', 'disclosure', 'corporate', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3710</th>\n",
       "      <td>Ekonomi Pembangunan</td>\n",
       "      <td>['abstrak', 'wenny', 'taufhan', 'mukti', 'pengaruh', 'tanam', 'modal', 'asing', 'tanam', 'modal'...</td>\n",
       "      <td>['abstract', 'penny', 'kaufman', 'hard', 'mufti', 'effect', 'foreign', 'investment', 'domestic',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>Ekonomi Pembangunan</td>\n",
       "      <td>['widayanti', 'determinan', 'tumbuh', 'kredit', 'perban', 'indonesia', 'studi', 'bank', 'periode...</td>\n",
       "      <td>['widayanti', 'determinant', 'credit', 'growth', 'bank', 'indonesia', 'case', 'study', 'commerci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9320</th>\n",
       "      <td>Psikologi</td>\n",
       "      <td>['abstrak', 'self', 'disclosure', 'remaja', 'putri', 'alami', 'obesitas', 'skripsi', 'program', ...</td>\n",
       "      <td>['abstract', 'self', 'disclosure', 'girl', 'obesity', 'thesis', 'psychology', 'department', 'fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>Manajemen</td>\n",
       "      <td>['abstrak', 'irwan', 'sugiantoro', 'analisis', 'portofolio', 'rangka', 'mengoptimalakan', 'tinga...</td>\n",
       "      <td>['abstract', 'iran', 'sugiantoro', 'portfolio', 'analysis', 'order', 'optimize', 'profit', 'leve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7476</th>\n",
       "      <td>Teknik Informatika</td>\n",
       "      <td>['identifikasi', 'atribut', 'citra', 'pejal', 'kaki', 'milik', 'kendala', 'dasar', 'sudut', 'lih...</td>\n",
       "      <td>['identification', 'attribute', 'pedestrian', 'image', 'still', 'fundamental', 'constraint', 'vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14101</th>\n",
       "      <td>Pendidikan Ipa</td>\n",
       "      <td>['tuju', 'teliti', 'layak', 'baca', 'hasil', 'ajar', 'respon', 'siswa', 'lembar', 'kerja', 'sisw...</td>\n",
       "      <td>['aim', 'research', 'know', 'validity', 'readable', 'learn', 'outcome', 'student', 'response', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              prodi  \\\n",
       "3207                  Ilmu Kelautan   \n",
       "4256                      Manajemen   \n",
       "8830                Ilmu Komunikasi   \n",
       "6853             Teknik Informatika   \n",
       "2495                     Agribisnis   \n",
       "1547   Teknologi Industri Pertanian   \n",
       "10778               Ekonomi Syariah   \n",
       "11821                          Pgsd   \n",
       "2980                  Agroteknologi   \n",
       "2081                     Agribisnis   \n",
       "11885                          Pgsd   \n",
       "10146                Sastra Inggris   \n",
       "9033                Ilmu Komunikasi   \n",
       "5513                      Akuntansi   \n",
       "3710            Ekonomi Pembangunan   \n",
       "3910            Ekonomi Pembangunan   \n",
       "9320                      Psikologi   \n",
       "4450                      Manajemen   \n",
       "7476             Teknik Informatika   \n",
       "14101                Pendidikan Ipa   \n",
       "\n",
       "                                                                                          abstrak_id_clean  \\\n",
       "3207   ['teliti', 'rumus', 'produksi', 'tingkat', 'minta', 'hambat', 'produksi', 'tidak', 'rempa', 'mou...   \n",
       "4256   ['abstrak', 'dasar', 'hasil', 'observasi', 'teliti', 'tenaga', 'didik', 'milik', 'motivasi', 'ke...   \n",
       "8830   ['abstrak', 'skripsi', 'judul', 'strategi', 'komunikasi', 'bpjs', 'sehat', 'puas', 'serta', 'bpj...   \n",
       "6853   ['teknologi', 'mobile', 'game', 'kembang', 'pesat', 'mobile', 'game', 'milik', 'minat', 'kalang'...   \n",
       "2495   ['lurah', 'tal', 'lurah', 'kota', 'diri', 'sentra', 'buat', 'takwa', 'jajan', 'khas', 'kota', 'd...   \n",
       "1547   ['kendali', 'mutu', 'proses', 'produksi', 'kerupuk', 'pul', 'tuju', 'mengi', 'dentifikasi', 'fak...   \n",
       "10778  ['skripsi', 'judul', 'analis', 'pengaruh', 'strategi', 'srgmentasi', 'targeting', 'positioning',...   \n",
       "11821  ['teliti', 'tuju', 'nilai', 'nilai', 'karakter', 'ekstrakurikuler', 'pencak', 'silat', 'tapak', ...   \n",
       "2980   ['abstrak', 'asap', 'cair', 'tempurung', 'kelapa', 'hasil', 'kondensasi', 'pirolisis', 'bahan', ...   \n",
       "2081   ['teliti', 'kabupaten', 'bangkal', 'tuju', 'karakteristik', 'responden', 'karakteristik', 'usaha...   \n",
       "11885  ['teliti', 'dilatarbelakangi', 'kurangnnya', 'media', 'ajar', 'ajar', 'ipa', 'sdn', 'kalijaten',...   \n",
       "10146  ['teliti', 'fokus', 'kohesi', 'leksikal', 'temu', 'lirik', 'lagu', 'jung', 'teliti', 'tuju', 'je...   \n",
       "9033   ['tuju', 'teliti', 'proses', 'komunikasi', 'non', 'verbal', 'karyawan', 'sandang', 'tuna', 'wica...   \n",
       "5513   ['teliti', 'tuju', 'uji', 'pengaruh', 'profitabilitas', 'leverage', 'ungkap', 'corporate', 'sosi...   \n",
       "3710   ['abstrak', 'wenny', 'taufhan', 'mukti', 'pengaruh', 'tanam', 'modal', 'asing', 'tanam', 'modal'...   \n",
       "3910   ['widayanti', 'determinan', 'tumbuh', 'kredit', 'perban', 'indonesia', 'studi', 'bank', 'periode...   \n",
       "9320   ['abstrak', 'self', 'disclosure', 'remaja', 'putri', 'alami', 'obesitas', 'skripsi', 'program', ...   \n",
       "4450   ['abstrak', 'irwan', 'sugiantoro', 'analisis', 'portofolio', 'rangka', 'mengoptimalakan', 'tinga...   \n",
       "7476   ['identifikasi', 'atribut', 'citra', 'pejal', 'kaki', 'milik', 'kendala', 'dasar', 'sudut', 'lih...   \n",
       "14101  ['tuju', 'teliti', 'layak', 'baca', 'hasil', 'ajar', 'respon', 'siswa', 'lembar', 'kerja', 'sisw...   \n",
       "\n",
       "                                                                                          abstrak_en_clean  \n",
       "3207   ['study', 'problem', 'formulation', 'production', 'increase', 'high', 'permintaanpun', 'occur', ...  \n",
       "4256   ['abstract', 'job', 'placement', 'urgent', 'matter', 'motivate', 'staff', 'work', 'place', 'yet'...  \n",
       "8830   ['abstract', 'thesis', 'entitle', 'communication', 'strategy', 'boy', 'kesehatan', 'boys', 'kese...  \n",
       "6853   ['mobile', 'game', 'technology', 'grow', 'rapidly', 'mobile', 'game', 'lot', 'enthusiast', 'vari...  \n",
       "2495   ['tinalan', 'urban', 'village', 'village', 'locate', 'city', 'keri', 'center', 'make', 'tofu', '...  \n",
       "1547   ['quality', 'control', 'production', 'process', 'aim', 'wheeze', 'puli', 'cracker', 'identify', ...  \n",
       "10778  ['study', 'entitle', 'analysis', 'influence', 'segmentation', 'target', 'position', 'strategy', ...  \n",
       "11821  ['purpose', 'research', 'understand', 'martial', 'art', 'tapas', 'ekstracuricullar', 'build', 's...  \n",
       "2980   ['abstract', 'liquid', 'smoke', 'coconut', 'shell', 'result', 'condensation', 'pyrolysis', 'orga...  \n",
       "2081   ['study', 'aim', 'analyze', 'characteristic', 'respondent', 'business', 'characteristic', 'jasmi...  \n",
       "11885  ['research', 'motivate', 'lack', 'learn', 'medium', 'science', 'learn', 'son', 'kalijaten', 'dis...  \n",
       "10146  ['study', 'focus', 'lexical', 'cohesion', 'word', 'find', 'jung', 'song', 'lyric', 'study', 'aim...  \n",
       "9033   ['purpose', 'research', 'know', 'nonverbal', 'communication', 'employee', 'speech', 'impair', 'c...  \n",
       "5513   ['study', 'aim', 'examine', 'effect', 'profitability', 'leverage', 'disclosure', 'corporate', 's...  \n",
       "3710   ['abstract', 'penny', 'kaufman', 'hard', 'mufti', 'effect', 'foreign', 'investment', 'domestic',...  \n",
       "3910   ['widayanti', 'determinant', 'credit', 'growth', 'bank', 'indonesia', 'case', 'study', 'commerci...  \n",
       "9320   ['abstract', 'self', 'disclosure', 'girl', 'obesity', 'thesis', 'psychology', 'department', 'fac...  \n",
       "4450   ['abstract', 'iran', 'sugiantoro', 'portfolio', 'analysis', 'order', 'optimize', 'profit', 'leve...  \n",
       "7476   ['identification', 'attribute', 'pedestrian', 'image', 'still', 'fundamental', 'constraint', 'vi...  \n",
       "14101  ['aim', 'research', 'know', 'validity', 'readable', 'learn', 'outcome', 'student', 'response', '...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Atur opsi tampilan agar tabel lebih rapi\n",
    "pd.set_option(\"display.max_colwidth\", 100)  # panjang teks tiap kolom max 100 karakter\n",
    "pd.set_option(\"display.max_rows\", 20)       # default tampilkan max 20 baris\n",
    "\n",
    "# === Baca file hasil preprocessing ===\n",
    "df_pre = pd.read_csv(\"Data/preprocessing_pta_all.csv\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "\n",
    "# === Ambil 20 baris acak (prodi, abstrak_id_clean, abstrak_en_clean) ===\n",
    "contoh = df_pre[[\"prodi\", \"abstrak_id_clean\", \"abstrak_en_clean\"]].sample(20, random_state=42)\n",
    "\n",
    "# === Tampilkan tabel rapi di Jupyter Notebook ===\n",
    "contoh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7554ed8",
   "metadata": {},
   "source": [
    "### Preprocessing Hasil Crawling PTA (Teknik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cba5ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\INFINIX\n",
      "[nltk_data]     EBC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data Fakultas Teknik: 2289\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prodi</th>\n",
       "      <th>abstrak_id_clean</th>\n",
       "      <th>abstrak_en_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6092</th>\n",
       "      <td>Teknik Industri</td>\n",
       "      <td>[portofolio, kumpul, saham, milik, investor, s...</td>\n",
       "      <td>[portfolio, collection, stock, own, investor, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6093</th>\n",
       "      <td>Teknik Industri</td>\n",
       "      <td>[pt, abc, usaha, gerak, bidang, manufaktur, ka...</td>\n",
       "      <td>[pt, arc, company, engage, manufacture, wood, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6094</th>\n",
       "      <td>Teknik Industri</td>\n",
       "      <td>[bangkal, salah, kabupaten, milik, potensi, al...</td>\n",
       "      <td>[bangkalan, one, district, potential, natural,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>Teknik Industri</td>\n",
       "      <td>[simulasi, duplikasi, abstraksi, hidup, nyata,...</td>\n",
       "      <td>[simulation, duplication, abstraction, real, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>Teknik Industri</td>\n",
       "      <td>[puas, tingkat, asa, layan, banding, kerja, ha...</td>\n",
       "      <td>[satisfaction, feel, level, someone, service, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                prodi                                   abstrak_id_clean  \\\n",
       "6092  Teknik Industri  [portofolio, kumpul, saham, milik, investor, s...   \n",
       "6093  Teknik Industri  [pt, abc, usaha, gerak, bidang, manufaktur, ka...   \n",
       "6094  Teknik Industri  [bangkal, salah, kabupaten, milik, potensi, al...   \n",
       "6095  Teknik Industri  [simulasi, duplikasi, abstraksi, hidup, nyata,...   \n",
       "6096  Teknik Industri  [puas, tingkat, asa, layan, banding, kerja, ha...   \n",
       "\n",
       "                                       abstrak_en_clean  \n",
       "6092  [portfolio, collection, stock, own, investor, ...  \n",
       "6093  [pt, arc, company, engage, manufacture, wood, ...  \n",
       "6094  [bangkalan, one, district, potential, natural,...  \n",
       "6095  [simulation, duplication, abstraction, real, l...  \n",
       "6096  [satisfaction, feel, level, someone, service, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.corpus import stopwords\n",
    "from spellchecker import SpellChecker\n",
    "import spacy\n",
    "\n",
    "# Download stopwords (sekali saja)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# === Load dataset ===\n",
    "pta_all = pd.read_csv(\"Data/pta_all.csv\")\n",
    "\n",
    "# === Daftar Prodi Fakultas Teknik ===\n",
    "prodi_teknik = [\n",
    "    \"Teknik Industri\",\n",
    "    \"Teknik Informatika\",\n",
    "    \"Manajemen Informatika\",\n",
    "    \"Teknik Multimedia Dan Jaringan\",\n",
    "    \"Mekatronika\",\n",
    "    \"Teknik Elektro\",\n",
    "    \"Sistem Informasi\",\n",
    "    \"Teknik Mesin\",\n",
    "    \"Teknik Mekatronika\"\n",
    "]\n",
    "\n",
    "# === Filter hanya Fakultas Teknik ===\n",
    "pta_teknik = pta_all[pta_all[\"prodi\"].isin(prodi_teknik)].copy()\n",
    "\n",
    "# === Stopwords ===\n",
    "stopwords_id = set(stopwords.words(\"indonesian\"))\n",
    "stopwords_en = set(stopwords.words(\"english\"))\n",
    "\n",
    "# === Stemmer Indonesia ===\n",
    "factory = StemmerFactory()\n",
    "stemmer_id = factory.create_stemmer()\n",
    "\n",
    "# === Spell checker English ===\n",
    "spell_en = SpellChecker(language=\"en\")\n",
    "\n",
    "# ========================\n",
    "# Fungsi Preprocessing Indo\n",
    "# ========================\n",
    "def preprocess_text_id(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # (2) Hapus tanda baca & simbol\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text.lower())\n",
    "    # (5) Tokenisasi\n",
    "    tokens = text.split()\n",
    "    if not tokens:\n",
    "        return []\n",
    "    # (1) Stopword removal\n",
    "    tokens = [w for w in tokens if w not in stopwords_id]\n",
    "    if not tokens:\n",
    "        return []\n",
    "    # (4) Stemming dengan Sastrawi\n",
    "    tokens = [stemmer_id.stem(w) for w in tokens]\n",
    "    return tokens\n",
    "\n",
    "# ========================\n",
    "# Fungsi Preprocessing English\n",
    "# ========================\n",
    "def preprocess_text_en(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # (2) Hapus tanda baca & simbol\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text.lower())\n",
    "    # (5) Tokenisasi\n",
    "    tokens = text.split()\n",
    "    if not tokens:\n",
    "        return []\n",
    "    # (3) Cek ejaan pembakuan kata (hindari None)\n",
    "    corrected = []\n",
    "    for w in tokens:\n",
    "        corr = spell_en.correction(w)\n",
    "        corrected.append(corr if corr is not None else w)\n",
    "    tokens = corrected\n",
    "    # (1) Stopword removal\n",
    "    tokens = [w for w in tokens if isinstance(w, str) and w not in stopwords_en]\n",
    "    if not tokens:\n",
    "        return []\n",
    "    # (4) Lematisasi dengan spaCy (hanya jika ada token)\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    tokens = [token.lemma_ for token in doc]\n",
    "    return tokens\n",
    "\n",
    "# === Terapkan ke abstrak Fakultas Teknik ===\n",
    "pta_teknik[\"abstrak_id_clean\"] = pta_teknik[\"abstrak_id\"].apply(preprocess_text_id)\n",
    "pta_teknik[\"abstrak_en_clean\"] = pta_teknik[\"abstrak_en\"].apply(preprocess_text_en)\n",
    "\n",
    "# === Simpan hasil ===\n",
    "pta_teknik.to_csv(\"preprocessing_pta_teknik.csv\", index=False)\n",
    "\n",
    "# Contoh hasil\n",
    "print(\"Jumlah data Fakultas Teknik:\", len(pta_teknik))\n",
    "display(pta_teknik[[\"prodi\", \"abstrak_id_clean\", \"abstrak_en_clean\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3394eda",
   "metadata": {},
   "source": [
    "### Preprocessing Hasil Crawling Web Berita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "244eaafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul_clean</th>\n",
       "      <th>isi_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[roy, suryo, alas, gelar, bedah, buku, jokowi,...</td>\n",
       "      <td>[tulis, bukujokowi, s, white, paperyaituroy, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[fadli, zon, gugat, adil, perkosa, massal]</td>\n",
       "      <td>[koalisi, masyarakat, sipil, lawan, impunitas,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[jusuf, kalla, tuntut, demo, cermin, kondisi, ...</td>\n",
       "      <td>[mantan, wakil, presidenjusuf, kallamengatakan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mu, ti, sekolah, kembali, smart, tv, kenan]</td>\n",
       "      <td>[menteri, didik, dasar, tengah, abdul, mu, ti,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[fraksi, gerindra, undur, rahayu, saraswati, m...</td>\n",
       "      <td>[fraksi, gerindra, aku, kaget, putus, undur, r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         judul_clean  \\\n",
       "0  [roy, suryo, alas, gelar, bedah, buku, jokowi,...   \n",
       "1         [fadli, zon, gugat, adil, perkosa, massal]   \n",
       "2  [jusuf, kalla, tuntut, demo, cermin, kondisi, ...   \n",
       "3       [mu, ti, sekolah, kembali, smart, tv, kenan]   \n",
       "4  [fraksi, gerindra, undur, rahayu, saraswati, m...   \n",
       "\n",
       "                                           isi_clean  \n",
       "0  [tulis, bukujokowi, s, white, paperyaituroy, s...  \n",
       "1  [koalisi, masyarakat, sipil, lawan, impunitas,...  \n",
       "2  [mantan, wakil, presidenjusuf, kallamengatakan...  \n",
       "3  [menteri, didik, dasar, tengah, abdul, mu, ti,...  \n",
       "4  [fraksi, gerindra, aku, kaget, putus, undur, r...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords (sekali saja)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# === Load dataset ===\n",
    "tempo_berita = pd.read_csv(\"Data/tempo_berita.csv\")\n",
    "\n",
    "# === Stopwords & Stemmer Indonesia ===\n",
    "stopwords_id = set(stopwords.words(\"indonesian\"))\n",
    "factory = StemmerFactory()\n",
    "stemmer_id = factory.create_stemmer()\n",
    "\n",
    "# ========================\n",
    "# Fungsi Preprocessing Indo\n",
    "# ========================\n",
    "def preprocess_text_id(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Menghilangkan simbol & tanda baca\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text.lower())\n",
    "    # Tokenisasi\n",
    "    tokens = text.split()\n",
    "    # Stopword removal\n",
    "    tokens = [w for w in tokens if w not in stopwords_id]\n",
    "    # Stemming dengan Sastrawi\n",
    "    tokens = [stemmer_id.stem(w) for w in tokens]\n",
    "    return tokens\n",
    "\n",
    "# === Terapkan ke Tempo ===\n",
    "tempo_berita[\"judul_clean\"] = tempo_berita[\"judul_berita\"].apply(preprocess_text_id)\n",
    "tempo_berita[\"isi_clean\"] = tempo_berita[\"isi_berita\"].apply(preprocess_text_id)\n",
    "\n",
    "# === Simpan hasil ===\n",
    "tempo_berita.to_csv(\"preprocessing_berita.csv\", index=False)\n",
    "\n",
    "# Contoh hasil\n",
    "tempo_berita[[\"judul_clean\", \"isi_clean\"]].head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
